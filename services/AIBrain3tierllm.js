// ============================================================================
// AI BRAIN 3-TIER LLM SERVICE
// ðŸ“‹ DESCRIPTION: Clean interface to AI Brain with 3-Tier Intelligence System
// ðŸŽ¯ PURPOSE: Single source of truth for all AI responses
// ðŸ”§ FEATURES: 
//     - Tier 1: Rule-Based matching (FREE - 80% of calls)
//     - Tier 2: Semantic matching (FREE - 14% of calls)
//     - Tier 3: LLM Fallback (GPT-4o-mini - 6% of calls, $0.04 each)
//     - Redis caching for sub-50ms performance
//     - Comprehensive logging and performance tracking
// âš ï¸  CRITICAL NOTES:
//     - This is the ONLY knowledge source in the system
//     - All responses come from AI Brain (Scenario Pool + 3-Tier Intelligence)
//     - Production UI intelligence settings control the tiers
//     - Always provides a response (Tier 3 LLM never fails)
// ============================================================================

const Company = require('../models/v2Company');
const { redisClient } = require('../clients');
const logger = require('../utils/logger');
const { replacePlaceholders } = require('../utils/placeholderReplacer');
const ResponseEngine = require('./ResponseEngine');

class AIBrain3tierllm {
    constructor() {
        this.performanceMetrics = {
            totalQueries: 0,
            tier1Hits: 0,
            tier2Hits: 0,
            tier3Hits: 0,
            avgResponseTime: 0,
            cacheHits: 0,
            lastOptimized: new Date()
        };
    }

    /**
     * ðŸŽ¯ QUERY AI BRAIN - THE ONLY INTELLIGENCE SOURCE
     * ðŸ“‹ Routes through 3-Tier Intelligence System based on production settings
     * âš ï¸  CRITICAL: This is the single entry point for ALL AI responses
     * 
     * @param {string} companyId - Company identifier
     * @param {string} query - User's question/input
     * @param {Object} context - Call context (callState, routingId, etc.)
     * @returns {Object} { confidence, response, metadata }
     */
    async query(companyId, query, context = {}) {
        const startTime = Date.now();
        const routingId = context.routingId || `ai-brain-${Date.now()}`;
        const perfCheckpoints = {};
        
        try {
            logger.info(`ðŸ§  [AI BRAIN] Processing query for company ${companyId}`, {
                routingId,
                query: query.substring(0, 100),
                callSource: context.callSource || 'production',
                isTest: context.isTest || false
            });

            // Try cache first
            const cacheStartTime = Date.now();
            const cacheKey = this.generateCacheKey(companyId, query);
            const cachedResult = await this.getCachedResult(cacheKey);
            perfCheckpoints.cacheCheck = Date.now() - cacheStartTime;
            
            if (cachedResult) {
                this.performanceMetrics.cacheHits++;
                const responseTime = Date.now() - startTime;
                logger.info(`âš¡ [AI BRAIN] Cache hit (${responseTime}ms)`, { routingId });
                
                return {
                    ...cachedResult,
                    metadata: {
                        ...cachedResult.metadata,
                        cached: true,
                        responseTime
                    }
                };
            }

            // Query the AI Brain (3-Tier Intelligence)
            const aiStartTime = Date.now();
            const result = await this.queryAIBrain(companyId, query, context);
            perfCheckpoints.aiBrainQuery = Date.now() - aiStartTime;

            // Cache successful results
            if (result.confidence > 0.5 && result.response) {
                const cacheWriteStart = Date.now();
                await this.cacheResult(cacheKey, result);
                perfCheckpoints.cacheWrite = Date.now() - cacheWriteStart;
            }

            // Update metrics
            const responseTime = Date.now() - startTime;
            this.performanceMetrics.totalQueries++;
            this.performanceMetrics.avgResponseTime = 
                (this.performanceMetrics.avgResponseTime * (this.performanceMetrics.totalQueries - 1) + responseTime) / 
                this.performanceMetrics.totalQueries;

            // Track tier usage
            const tierUsed = result.metadata?.trace?.tierUsed;
            if (tierUsed === 1) this.performanceMetrics.tier1Hits++;
            if (tierUsed === 2) this.performanceMetrics.tier2Hits++;
            if (tierUsed === 3) this.performanceMetrics.tier3Hits++;

            // ðŸŽ¯ PERFORMANCE SUMMARY - Crystal clear visibility
            const tierEmoji = tierUsed === 1 ? 'âš¡' : tierUsed === 2 ? 'ðŸ§ ' : tierUsed === 3 ? 'ðŸ¤–' : 'â“';
            const tierName = tierUsed === 1 ? 'TIER 1 (Rule-Based)' : tierUsed === 2 ? 'TIER 2 (Semantic)' : tierUsed === 3 ? 'TIER 3 (LLM)' : 'UNKNOWN';
            const cost = result.metadata?.trace?.cost?.total || 0;
            const costDisplay = cost > 0 ? `$${cost.toFixed(4)}` : '$0.00 (FREE)';

            console.log('\n' + 'â•'.repeat(80));
            console.log(`${tierEmoji} AI BRAIN PERFORMANCE SUMMARY`);
            console.log('â•'.repeat(80));
            console.log(`ðŸ“ž Query: "${query.substring(0, 60)}${query.length > 60 ? '...' : ''}"`);
            console.log(`ðŸŽ¯ Tier Used: ${tierName}`);
            console.log(`ðŸ’° Cost: ${costDisplay}`);
            console.log(`â±ï¸  Total Time: ${responseTime}ms`);
            console.log(`   â”œâ”€ Cache Check: ${perfCheckpoints.cacheCheck}ms`);
            console.log(`   â”œâ”€ AI Brain Query: ${perfCheckpoints.aiBrainQuery}ms`);
            if (perfCheckpoints.cacheWrite) {
                console.log(`   â””â”€ Cache Write: ${perfCheckpoints.cacheWrite}ms`);
            }
            console.log(`ðŸ“Š Confidence: ${(result.confidence * 100).toFixed(1)}%`);
            if (result.metadata?.scenarioName) {
                console.log(`ðŸŽ¬ Scenario: ${result.metadata.scenarioName}`);
            }
            console.log('â•'.repeat(80) + '\n');

            logger.info(`âœ… [AI BRAIN] Query complete (${responseTime}ms)`, {
                routingId,
                confidence: result.confidence,
                tierUsed,
                tierName,
                cost,
                perfCheckpoints
            });

            return {
                ...result,
                metadata: {
                    ...result.metadata,
                    responseTime
                }
            };

        } catch (error) {
            logger.error(`âŒ [AI BRAIN] Query failed`, {
                routingId,
                companyId,
                error: error.message,
                stack: error.stack
            });

            // ðŸ”¥ NO FALLBACK TEXT! If AI Brain fails, return null to trigger transfer
            return {
                confidence: 0,
                response: null,  // âŒ NO GENERIC TEXT! Force transfer to human
                metadata: {
                    source: 'ai-brain-critical-failure',
                    error: error.message,
                    responseTime: Date.now() - startTime,
                    action: 'transfer'  // System should transfer to human
                }
            };
        }
    }

    /**
     * ðŸ§  QUERY AI BRAIN - 3-TIER INTELLIGENCE SYSTEM
     * This is where all the magic happens!
     */
    async queryAIBrain(companyId, query, context) {
        try {
            const HybridScenarioSelector = require('./HybridScenarioSelector');
            const ScenarioPoolService = require('./ScenarioPoolService');
            const GlobalInstantResponseTemplate = require('../models/GlobalInstantResponseTemplate');
            const IntelligentRouter = require('./IntelligentRouter');
            const AdminSettings = require('../models/AdminSettings');
            
            logger.info(`âš¡ [AI BRAIN] Loading scenarios and intelligence config`, {
                routingId: context.routingId
            });

            // Load company configuration
            const company = await Company.findById(companyId)
                .select('configuration aiAgentSettings aiAgentSettings')
                .lean();

            if (!company) {
                return {
                    confidence: 0,
                    response: null,
                    metadata: {
                        source: 'ai-brain',
                        error: 'Company not found'
                    }
                };
            }

            // Determine intelligence settings (Global vs Custom)
            const useGlobalIntelligence = company?.aiAgentSettings?.useGlobalIntelligence !== false;
            let intelligenceEnabled = false;
            let intelligenceConfig = null;
            
            if (useGlobalIntelligence) {
                const adminSettings = await AdminSettings.findOne({});
                const globalIntelligence = adminSettings?.globalProductionIntelligence || {};
                intelligenceEnabled = globalIntelligence.enabled === true;
                intelligenceConfig = globalIntelligence;
                
                logger.info(`ðŸŒ [AI BRAIN] Using GLOBAL intelligence settings`, {
                    routingId: context.routingId,
                    enabled: intelligenceEnabled,
                    tier1: globalIntelligence.thresholds?.tier1 || 0.80,
                    tier2: globalIntelligence.thresholds?.tier2 || 0.60,
                    tier3Enabled: globalIntelligence.thresholds?.enableTier3
                });
            } else {
                const productionIntelligence = company?.aiAgentSettings?.productionIntelligence || {};
                intelligenceEnabled = productionIntelligence.enabled === true;
                intelligenceConfig = productionIntelligence;
                
                logger.info(`ðŸŽ¯ [AI BRAIN] Using CUSTOM intelligence settings`, {
                    routingId: context.routingId,
                    enabled: intelligenceEnabled,
                    tier1: productionIntelligence.thresholds?.tier1 || 0.80,
                    tier2: productionIntelligence.thresholds?.tier2 || 0.60,
                    tier3Enabled: productionIntelligence.thresholds?.enableTier3
                });
            }

            // Load scenarios from AI Brain (Scenario Pool)
            const { scenarios, templatesUsed } = await ScenarioPoolService.getScenarioPoolForCompany(companyId);
            
            if (!templatesUsed || templatesUsed.length === 0) {
                logger.info(`â„¹ï¸ [AI BRAIN] No templates configured for company`, {
                    routingId: context.routingId
                });
                return {
                    confidence: 0,
                    response: null,
                    metadata: {
                        source: 'ai-brain',
                        reason: 'No AI Brain templates assigned to company'
                    }
                };
            }

            // Filter to only enabled scenarios
            const enabledScenarios = scenarios.filter(s => s.isEnabledForCompany !== false);
            
            if (enabledScenarios.length === 0) {
                return {
                    confidence: 0,
                    response: null,
                    metadata: {
                        source: 'ai-brain',
                        reason: 'No enabled scenarios (all disabled)'
                    }
                };
            }

            logger.info(`ðŸ§  [AI BRAIN] Loaded ${enabledScenarios.length} enabled scenarios from ${templatesUsed.length} template(s)`);

            // Route through appropriate intelligence tier
            let result;
            
            if (intelligenceEnabled) {
                // ============================================
                // ðŸš€ 3-TIER INTELLIGENCE (PRODUCTION MODE)
                // ============================================
                logger.info(`ðŸš€ [AI BRAIN] Using 3-Tier Intelligence (Tier 1 â†’ 2 â†’ 3)`, {
                    routingId: context.routingId,
                    mode: useGlobalIntelligence ? 'GLOBAL' : 'CUSTOM'
                });
                
                const primaryTemplate = await GlobalInstantResponseTemplate.findById(templatesUsed[0].templateId);
                
                if (!primaryTemplate) {
                    return {
                        confidence: 0,
                        response: null,
                        metadata: {
                            source: 'ai-brain',
                            error: 'Primary template not found'
                        }
                    };
                }
                
                const router = IntelligentRouter;
                
                const routingResult = await router.route({
                    callerInput: query,
                    template: primaryTemplate,
                    company: company,
                    callId: context.callState?.callId || context.routingId,
                    context: {
                        callSource: context.callSource || 'production',
                        isTest: context.isTest || false,
                        callState: context.callState,
                        intelligenceConfig,
                        routingId: context.routingId
                    }
                });
                
                logger.info(`âœ… [AI BRAIN] 3-Tier routing complete`, {
                    routingId: context.routingId,
                    matched: routingResult.matched,
                    tierUsed: routingResult.tierUsed,
                    confidence: routingResult.confidence,
                    cost: routingResult.cost?.total || 0
                });
                
                if (routingResult.matched && routingResult.scenario) {
                    result = {
                        scenario: routingResult.scenario,
                        confidence: routingResult.confidence,
                        score: routingResult.confidence,
                        response: routingResult.response,  // âœ… CRITICAL FIX: Include response from router
                        trace: {
                            tierUsed: routingResult.tierUsed,
                            tier1Score: routingResult.tier1Result?.confidence || 0,
                            tier2Score: routingResult.tier2Result?.confidence || 0,
                            tier3Score: routingResult.tier3Result?.confidence || 0,
                            timingMs: routingResult.performance || {},
                            cost: routingResult.cost || {}
                        }
                    };
                } else {
                    result = {
                        scenario: null,
                        confidence: 0,
                        score: 0,
                        trace: { tierUsed: routingResult.tierUsed, reason: 'No match above thresholds' }
                    };
                }
                
            } else {
                // ============================================
                // ðŸŽ¯ TIER 1 ONLY (LEGACY/TESTING MODE)
                // ============================================
                logger.info(`ðŸŽ¯ [AI BRAIN] Using Tier 1 only (3-Tier disabled)`, {
                    routingId: context.routingId
                });
                
                const allFillers = [
                    ...(company.configuration?.fillerWords?.inherited || []),
                    ...(company.configuration?.fillerWords?.custom || []),
                    ...(company.aiAgentSettings?.fillerWords?.custom || [])
                ];
                const effectiveFillers = [...new Set(allFillers)];
                
                const urgencyKeywords = [
                    ...(company.configuration?.urgencyKeywords?.inherited || []),
                    ...(company.configuration?.urgencyKeywords?.custom || [])
                ];
                
                const selector = new HybridScenarioSelector(effectiveFillers, urgencyKeywords, null);

                const matchContext = {
                    channel: context.channel || 'voice',
                    language: context.language || 'auto',
                    conversationState: context.callState || {}
                };

                result = await selector.selectScenario(query, enabledScenarios, matchContext);
            }
            
            // Process result and return response
            if (result.scenario && result.confidence > 0) {
                logger.info(`âœ… [AI BRAIN] Scenario matched!`, {
                    routingId: context.routingId,
                    scenarioId: result.scenario.scenarioId,
                    name: result.scenario.name,
                    confidence: result.confidence.toFixed(3)
                });

                // âœ… CRITICAL FIX: Use response from router if available, otherwise extract from scenario
                let selectedReply;
                let replyType = 'full'; // Default reply type
                
                if (result.response) {
                    // Router already selected the response (Tier 1/2/3)
                    selectedReply = result.response;
                    // Infer reply type from response length (just for metadata)
                    replyType = result.response.length < 100 ? 'quick' : 'full';
                } else {
                    // ðŸŽ¯ PHASE 2: RESPONSE ENGINE - CENTRALIZED REPLY SELECTION
                    // Delegate ALL reply selection to Response Engine based on:
                    // - scenarioType (INFO_FAQ, ACTION_FLOW, SYSTEM_ACK, SMALL_TALK)
                    // - replyStrategy (AUTO, FULL_ONLY, QUICK_ONLY, QUICK_THEN_FULL, LLM_WRAP, LLM_CONTEXT)
                    // - channel (voice, sms, chat)
                    
                    const channel = context && context.channel ? context.channel : 'voice';
                    
                    try {
                        const responseEngineResult = await ResponseEngine.buildResponse({
                            scenario: result.scenario,
                            channel,
                            context
                        });
                        
                        selectedReply = responseEngineResult.text;
                        replyType = responseEngineResult.strategyUsed.includes('QUICK') ? 'quick' : 'full';
                        
                        // Add Response Engine metadata for tracing
                        result.scenarioTypeResolved = responseEngineResult.scenarioTypeResolved;
                        result.replyStrategyResolved = responseEngineResult.replyStrategyResolved;
                        result.responseStrategyUsed = responseEngineResult.strategyUsed;
                        
                        // ðŸŽ¯ PHASE A â€“ STEP 3A: Store follow-up metadata for runtime use
                        result.followUp = responseEngineResult.followUp;
                        
                    } catch (error) {
                        logger.error('ðŸš¨ [AI BRAIN] Response Engine failed, no fallback', {
                            routingId: context.routingId,
                            error: error.message,
                            scenarioId: result.scenario?.scenarioId,
                            scenarioName: result.scenario?.name
                        });
                        selectedReply = null;  // âŒ NO FALLBACK TEXT!
                    }
                }
                
                // ðŸ”¥ If no reply found, return null (no processing)
                const processedResponse = selectedReply ? replacePlaceholders(selectedReply, company) : null;

                return {
                    confidence: result.confidence,
                    response: processedResponse,  // null if scenario has no replies
                    metadata: {
                        source: 'ai-brain',
                        scenarioId: result.scenario.scenarioId,
                        scenarioName: result.scenario.name,
                        replyType: replyType,
                        matchScore: result.score,
                        trace: result.trace,
                        // ðŸŽ¯ PHASE 2: Response Engine metadata
                        scenarioTypeResolved: result.scenarioTypeResolved,
                        replyStrategyResolved: result.replyStrategyResolved,
                        responseStrategyUsed: result.responseStrategyUsed,
                        // ðŸŽ¯ PHASE A â€“ STEP 3A: Follow-up metadata (for Twilio runtime in Phase 3B)
                        followUp: result.followUp || {
                            mode: 'NONE',
                            questionText: null,
                            transferTarget: null
                        }
                    }
                };
            }

            logger.info(`â„¹ï¸ [AI BRAIN] No scenario matched`, {
                routingId: context.routingId,
                bestScore: result.score || 0
            });

            return {
                confidence: 0,
                response: null,
                metadata: {
                    source: 'ai-brain',
                    reason: 'No scenario matched above threshold',
                    trace: result.trace
                }
            };

        } catch (error) {
            logger.error(`âŒ [AI BRAIN] Error in queryAIBrain`, {
                routingId: context.routingId,
                error: error.message
            });

            return {
                confidence: 0,
                response: null,
                metadata: {
                    source: 'ai-brain',
                    error: error.message
                }
            };
        }
    }

    // ============================================
    // ðŸš€ CACHING & PERFORMANCE HELPERS
    // ============================================

    generateCacheKey(companyId, query) {
        const normalizedQuery = query.toLowerCase().trim().substring(0, 100);
        return `ai-brain:${companyId}:${Buffer.from(normalizedQuery).toString('base64').substring(0, 50)}`;
    }

    async getCachedResult(cacheKey) {
        try {
            if (redisClient && redisClient.isReady) {
                const cached = await redisClient.get(cacheKey);
                if (cached) {
                    return JSON.parse(cached);
                }
            }
        } catch (error) {
            logger.warn(`âš ï¸ [AI BRAIN] Cache read failed`, { error: error.message });
        }
        return null;
    }

    async cacheResult(cacheKey, result) {
        try {
            if (redisClient && redisClient.isReady) {
                await redisClient.setEx(cacheKey, 300, JSON.stringify(result)); // 5min TTL
            }
        } catch (error) {
            logger.warn(`âš ï¸ [AI BRAIN] Cache write failed`, { error: error.message });
        }
    }

    getPerformanceMetrics() {
        return {
            ...this.performanceMetrics,
            tier1Percentage: (this.performanceMetrics.tier1Hits / this.performanceMetrics.totalQueries * 100).toFixed(1),
            tier2Percentage: (this.performanceMetrics.tier2Hits / this.performanceMetrics.totalQueries * 100).toFixed(1),
            tier3Percentage: (this.performanceMetrics.tier3Hits / this.performanceMetrics.totalQueries * 100).toFixed(1),
            cacheHitRate: (this.performanceMetrics.cacheHits / this.performanceMetrics.totalQueries * 100).toFixed(1)
        };
    }
}

// Export singleton instance
module.exports = new AIBrain3tierllm();

