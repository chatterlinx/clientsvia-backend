# üìä AGENT CONSOLE - COMPREHENSIVE AUDIT
## ClientVia AI Agent Platform - Complete System Architecture

**Date:** February 24, 2026  
**Auditor:** AI Assistant  
**Scope:** Agent Console, Agent 2.0 Discovery, Triggers, Twilio Integration  
**Purpose:** World-class enterprise-level documentation for Call 2.0 development

---

## üéØ EXECUTIVE SUMMARY

The Agent Console is a sophisticated multi-tier AI agent orchestration system that powers phone conversations for service businesses. The system has:

- **4 Main Pages**: Index (Dashboard), Agent 2.0 Discovery, Triggers Console, Global Hub, Booking Logic
- **7 Modals**: Greeting Rule Editor, Trigger Editor, Group Creator, GPT Settings, Approval Modal
- **3 Core Engines**: Discovery Engine, Trigger Matching, Booking Flow
- **2 Integration Points**: Twilio (inbound calls), ElevenLabs (audio generation)

---

## üìÅ FILE STRUCTURE & ORGANIZATION

### **Frontend Files (Public)**
```
/public/agent-console/
‚îú‚îÄ‚îÄ index.html              # Dashboard / Landing page
‚îú‚îÄ‚îÄ index.js                # Dashboard controller
‚îú‚îÄ‚îÄ agent2.html             # Agent 2.0 Discovery configuration page
‚îú‚îÄ‚îÄ agent2.js               # Discovery engine controller (1554 lines)
‚îú‚îÄ‚îÄ triggers.html           # Trigger cards management page
‚îú‚îÄ‚îÄ triggers.js             # Trigger console controller (1776+ lines)
‚îú‚îÄ‚îÄ global-hub.html         # Global dictionaries & platform defaults
‚îú‚îÄ‚îÄ global-hub.js           # Global hub controller
‚îú‚îÄ‚îÄ booking.html            # Booking logic configuration
‚îú‚îÄ‚îÄ booking.js              # Booking flow controller
‚îú‚îÄ‚îÄ calendar.html           # Google Calendar integration
‚îú‚îÄ‚îÄ calendar.js             # Calendar controller
‚îú‚îÄ‚îÄ styles.css              # Shared styles for all pages
‚îî‚îÄ‚îÄ lib/
    ‚îî‚îÄ‚îÄ auth.js             # Centralized authentication module
```

### **Backend Routes**
```
/routes/
‚îú‚îÄ‚îÄ v2twilio.js                    # Main Twilio webhook handler (5577+ lines)
‚îú‚îÄ‚îÄ admin/
‚îÇ   ‚îú‚îÄ‚îÄ agent2.js                  # Agent 2.0 configuration API
‚îÇ   ‚îú‚îÄ‚îÄ greetings.js               # Greetings system API (1462+ lines)
‚îÇ   ‚îú‚îÄ‚îÄ companyTriggers.js         # Trigger management API
‚îÇ   ‚îî‚îÄ‚îÄ globalTriggers.js          # Global trigger groups API
‚îî‚îÄ‚îÄ agentConsole/
    ‚îî‚îÄ‚îÄ agentConsole.js            # Agent Console backend routes
```

### **Database Models**
```
/models/
‚îî‚îÄ‚îÄ v2Company.js
    ‚îî‚îÄ‚îÄ aiAgentSettings.agent2
        ‚îú‚îÄ‚îÄ greetings                  # Greeting system config
        ‚îÇ   ‚îú‚îÄ‚îÄ callStart              # Outbound greeting
        ‚îÇ   ‚îî‚îÄ‚îÄ interceptor            # Inbound greeting responses
        ‚îú‚îÄ‚îÄ triggers                   # Trigger cards (local)
        ‚îú‚îÄ‚îÄ globalTriggerGroupId       # Active global trigger group
        ‚îî‚îÄ‚îÄ discovery                  # Discovery flow settings
```

---

## üéôÔ∏è PART 1: GREETINGS SYSTEM (Entry Point)

### **Purpose**
Two-phase greeting system that controls the first moments of a call:
1. **Call Start Greeting** - Agent speaks first when call connects
2. **Greeting Interceptor** - Responds to caller's short greetings ("hi", "hello")

### **Call Start Greeting**
**File:** `agent2.html` (lines 143-198)  
**JavaScript:** `agent2.js` (lines 64-70, 755-766, 912-1032)  
**Backend:** `routes/admin/greetings.js` (lines 224-273, 329-418)

**Database Schema:**
```javascript
{
  callStart: {
    enabled: Boolean,              // Toggle on/off
    text: String,                  // TTS text (max 500 chars)
    audioUrl: String,              // Pre-generated ElevenLabs URL
    audioTextHash: String,         // For cache invalidation
    audioGeneratedAt: Date
  }
}
```

**Flow:**
1. User enters text in Agent Console ‚Üí `agent2.html` line 160
2. On blur, saves via API ‚Üí `agent2.js` line 912 `saveCallStartGreeting()`
3. User clicks "Generate" ‚Üí `agent2.js` line 949 `generateCallStartAudio()`
4. Backend calls ElevenLabs ‚Üí `greetings.js` line 329 `POST /:companyId/greetings/call-start/audio`
5. Audio stored in `/public/audio/greetings/`
6. Twilio calls webhook ‚Üí `v2twilio.js` uses this greeting for first utterance

### **Greeting Interceptor**
**File:** `agent2.html` (lines 200-288)  
**JavaScript:** `agent2.js` (lines 71-79, 814-905)  
**Backend:** `routes/admin/greetings.js` (lines 419-582)

**Database Schema:**
```javascript
{
  interceptor: {
    enabled: Boolean,
    shortOnlyGate: {
      maxWords: Number (1-5),            // Only fire if input ‚â§ this many words
      blockIfIntentWords: Boolean        // Skip if caller has business intent
    },
    intentWords: [String],               // Business keywords (repair, AC, etc)
    rules: [{
      ruleId: String (unique),
      enabled: Boolean,
      priority: Number (1-1000),
      matchType: 'EXACT' | 'FUZZY' | 'CONTAINS' | 'REGEX',
      triggers: [String],                // ["hi", "hello", "hey"]
      response: String (max 300 chars),
      audioUrl: String,
      audioTextHash: String,
      audioGeneratedAt: Date,
      createdAt: Date,
      updatedAt: Date
    }]
  }
}
```

**Short-Only Gate** (Prevents Hijacking):
- Caller says "hi my AC is broken" ‚Üí 4 words ‚Üí **blocked**
- Caller says "hello" ‚Üí 1 word ‚Üí **matches**
- Caller says "good morning" ‚Üí 2 words ‚Üí **matches** (if maxWords = 2)

**Intent Word Blocking:**
- If input contains words like: repair, maintenance, AC, broken ‚Üí skip greeting, go straight to triggers

**Greeting Rules Table** (UI Component):
- **Location:** `agent2.html` lines 258-286
- **Rendering:** `agent2.js` lines 814-905
- **Columns:** On/Off Toggle, Priority, Match Type, Triggers, Response, Audio, Actions

---

## üéØ PART 2: TRIGGER CARDS SYSTEM

### **Purpose**
Intent matching engine that routes caller questions to appropriate responses. Triggers are the "brain" of the system - they detect what the caller wants and provide answers.

### **Architecture**

**Files:**
- **Frontend:** `triggers.html` (1380 lines), `triggers.js` (1776+ lines)
- **Backend:** `routes/admin/agent2.js`, `routes/admin/companyTriggers.js`

**Two-Tier System:**
1. **Global Triggers** - Platform-wide, shared across companies (HVAC, Dental, etc.)
2. **Local Triggers** - Company-specific overrides

### **Global Trigger Groups**

**Group Selector:**
- **Location:** `triggers.html` lines 860-880
- **Dropdown:** Shows available groups (HVAC ‚ùÑÔ∏è, Dental ü¶∑, Plumbing üîß, etc.)
- **Backend:** `/api/admin/agent2/global/groups`

**Stats Bar:**
- **Location:** `triggers.html` lines 882-903
- **Displays:**
  - Global triggers (inherited from group)
  - Local triggers (company-specific)
  - Overrides (local copies of global triggers)
  - Total active
  - Total disabled

### **Trigger Data Model**

```javascript
{
  triggerId: String (unique),
  ruleId: String,                    // category.topic format
  label: String,                     // Display name
  priority: Number (1-1000),         // Lower = higher priority
  
  // Matching rules
  match: {
    keywords: [String],              // All must appear (flexible order)
    phrases: [String],               // Exact phrase must appear
    negative: [String]               // If matched, trigger won't fire
  },
  
  // Response (Standard Mode)
  answer: {
    text: String,                    // Answer text
    audioUrl: String,                // Pre-generated audio
    audioTextHash: String,           // For cache invalidation
    audioGeneratedAt: Date
  },
  
  // Response (LLM Fact Pack Mode)
  llm: {
    included: String (max 2500),     // What's included
    excluded: String (max 2500),     // What's not included
    backup: String (max 500)         // Fallback if LLM fails
  },
  
  followup: String,                  // Follow-up question
  scope: 'GLOBAL' | 'LOCAL',
  enabled: Boolean,
  
  createdAt: Date,
  updatedAt: Date
}
```

### **Response Modes**

**1. Standard Mode** (Pre-recorded Audio)
- **UI:** `triggers.html` lines 1095-1128
- **Audio Generation:** Click "Generate" ‚Üí calls ElevenLabs
- **Audio Storage:** `/public/audio/triggers/`
- **Cache Invalidation:** Text hash comparison

**2. LLM Fact Pack Mode** (Dynamic AI)
- **UI:** `triggers.html` lines 1131-1184
- **Fields:**
  - `included` - What IS included (facts)
  - `excluded` - What is NOT included (disclaimers)
  - `backup` - Required fallback answer
- **Rendering:** Always uses live TTS via ElevenLabs (no pre-recorded audio)
- **LLM:** Generates 1-2 sentence responses using ONLY provided facts

### **GPT-4 Prefill Feature**

**Purpose:** Auto-generate trigger content from keywords using AI

**UI:**
- **Settings Modal:** `triggers.html` lines 1247-1313
- **Prefill Button:** `triggers.html` line 1052

**Settings:**
- Business Type (HVAC, Dental, Plumbing, etc.)
- Default Priority
- Tone (Friendly, Professional, Casual, Empathetic)
- Custom Instructions
- Include Follow-up Questions (checkbox)

**Flow:**
1. User enters keywords: "service call, diagnostic fee"
2. Clicks "GPT-4 Prefill"
3. Backend calls OpenAI with business context
4. Auto-fills: phrases, negative keywords, answer text, follow-up question

---

## üîÑ PART 3: COMPLETE CALL FLOW (Twilio Entry to End)

### **Phase 0: Call Arrives**

**Entry Point:** `routes/v2twilio.js` line 5577+ (webhook endpoint)

```javascript
POST /api/v2/twilio/voice
```

**Flow:**
1. Twilio forwards call to webhook
2. Extract: `CallSid`, `From` (caller phone), `To` (business phone)
3. Lookup company by Twilio phone number
4. Load company configuration (including agent2 settings)
5. Initialize call state in Redis/StateStore
6. Compute AW Truth Proof (awHash + effectiveConfigVersion)

### **Phase 1: Call Start Greeting**

**Location:** `v2twilio.js` lines 124-195 (greeting validator)

**Flow:**
1. Check if `callStart.enabled` = true
2. Load `callStart.text` from database
3. Validate text (prevent code/JSON from being read)
4. If `callStart.audioUrl` exists ‚Üí Use `<Play>`
5. Else ‚Üí Use `<Say>` with TTS
6. Append `<Gather>` to listen for caller response

**TwiML Response:**
```xml
<Response>
  <Play>https://clientsvia.com/audio/greetings/call-start-abc123.mp3</Play>
  <Gather input="speech" timeout="5" speechTimeout="auto">
    <Pause length="1"/>
  </Gather>
</Response>
```

### **Phase 2: Caller Responds**

**Webhook:** `/api/v2/twilio/gather` (speech result)

**Flow:**
1. Receive STT result from Twilio
2. STT Preprocessing (filler removal, corrections)
3. **Check Greeting Interceptor** (BEFORE triggers)
   - Word count check (maxWords gate)
   - Intent word blocking
   - Rule matching (priority order)
   - If match ‚Üí respond with greeting, skip to next turn
4. If no greeting match ‚Üí proceed to Discovery Engine

### **Phase 3: Discovery Engine (Agent 2.0)**

**Backend Service:** `services/Agent2DiscoveryRunner.js` (inferred)

**Flow:**
1. Load active trigger group + local triggers
2. Merge globals with local overrides
3. Sort by priority (ascending = higher priority first)
4. For each trigger:
   - Check negative keywords ‚Üí skip if matched
   - Check keywords ‚Üí all must appear (flexible order)
   - Check phrases ‚Üí exact phrase must appear
5. First match wins
6. Execute response (Standard or LLM)

**Standard Mode Response:**
- If `audioUrl` exists ‚Üí `<Play>`
- Else ‚Üí `<Say>` with text
- If `followup` exists ‚Üí append follow-up question
- `<Gather>` for next turn

**LLM Mode Response:**
- Send caller input + fact pack to OpenAI
- Generate 1-2 sentence response
- If LLM fails ‚Üí use `backup` answer
- Convert to speech via ElevenLabs TTS
- `<Play>` generated audio
- If `followup` exists ‚Üí append follow-up
- `<Gather>` for next turn

### **Phase 4: Booking Consent Detection**

**Location:** `agent2.html` lines 290-305 (consent phrases config)

**Consent Phrases:**
```javascript
['yes', 'yeah', 'sure', 'ok', 'okay', 'yes please', 'that works', 'sounds good']
```

**Flow:**
1. After agent responds, listen for caller reply
2. Check if reply matches consent phrase
3. If matched ‚Üí build handoff payload (AC1 contract)
4. Hand off to Booking Logic engine

### **Handoff Contract (AC1)**

**Structure:**
```javascript
{
  handoffContractVersion: "AC1",
  companyId: "...",
  callSid: "...",
  fromPhone: "+15551234567",
  assumptions: {
    firstName: "...",
    lastName: "..."
  },
  summary: {
    issue: "...",
    serviceType: "...",
    urgency: "routine|urgent|emergency"
  }
}
```

**Display:** `agent2.html` lines 407-434

### **Phase 5: Booking Logic**

**File:** `booking.html`, `booking.js`  
**Backend:** `routes/controlPlane/bookingLogic.js`

**Flow:**
1. Receive handoff payload
2. Ask for customer details (if missing)
3. Check Google Calendar availability
4. Offer time slots
5. Confirm appointment
6. Send confirmation

### **Phase 6: Escalation**

**Escalation Phrases:**
```javascript
['speak to a human', 'talk to someone', 'real person', 'operator', 'representative']
```

**Location:** `agent2.html` lines 307-322

**Flow:**
1. Detect escalation phrase
2. Transfer to live operator
3. Use Twilio `<Dial>` verb

---

## üé® PART 4: UI COMPONENTS & MODALS

### **Modals Inventory**

#### **1. Greeting Rule Modal**
- **File:** `agent2.html` lines 450-528
- **Purpose:** Add/Edit greeting interceptor rules
- **Fields:**
  - Priority (1-1000)
  - Match Type (EXACT, FUZZY, CONTAINS, REGEX)
  - Triggers (comma-separated)
  - Response text (max 300 chars)
  - Audio URL (generated)
- **Actions:** Save, Cancel, Generate Audio, Play Audio

#### **2. Trigger Edit Modal**
- **File:** `triggers.html` lines 1009-1215
- **Purpose:** Add/Edit trigger cards
- **Fields:**
  - Label
  - Rule ID (category.topic format)
  - Priority
  - Keywords (comma-separated)
  - Phrases (comma-separated)
  - Negative keywords
  - **Response Mode Toggle:** Standard vs LLM
  - Answer text (Standard mode)
  - LLM fact pack (LLM mode)
    - Included facts
    - Excluded facts
    - Backup answer
  - Follow-up question
  - Audio URL (Standard mode only)
  - Scope (Local checkbox)
- **Actions:** Save, Cancel, Generate Audio, Play Audio, GPT-4 Prefill

#### **3. GPT Settings Modal**
- **File:** `triggers.html` lines 1247-1313
- **Purpose:** Configure GPT-4 prefill behavior
- **Fields:**
  - Business Type (dropdown)
  - Default Priority
  - Tone (dropdown)
  - Additional Instructions
  - Include Follow-up Questions (checkbox)

#### **4. Create Group Modal**
- **File:** `triggers.html` lines 1315-1374
- **Purpose:** Create new global trigger group
- **Warning Banner:** "This is NOT a trigger card!"
- **Fields:**
  - Group ID (alphanumeric + hyphens)
  - Name
  - Icon (emoji)
  - Description

#### **5. Approval Modal**
- **File:** `triggers.html` lines 1217-1244
- **Purpose:** Confirm destructive actions (delete, disable global trigger)
- **Requires:** User types "approved" to confirm

### **Shared UI Components**

#### **Toggle Switch**
- **Location:** `triggers.html` lines 388-466 (CSS)
- **Usage:** Enable/disable greetings, rules, triggers
- **States:** ON (blue) / OFF (gray)

#### **Response Mode Toggle**
- **Location:** `triggers.html` lines 256-297 (CSS)
- **Purpose:** Switch between Standard and LLM Fact Pack modes
- **Design:** Dark background, pill-shaped buttons

#### **Audio Generation Controls**
- **Components:**
  - Text input (readonly URL display)
  - Play button (toggle play/pause)
  - Generate button (calls ElevenLabs)
  - Status hint (audio ready, stale, missing)

#### **Stat Boxes**
- **Location:** `agent2.html` lines 102-132
- **Display:** Trigger count, clarifiers, vocabulary
- **Click Action:** Navigate to Trigger Console

#### **Health Status Bar**
- **Location:** `agent2.html` lines 94-100
- **Purpose:** Minimal issues-only display
- **States:**
  - ‚úÖ All systems operational (green)
  - ‚ö†Ô∏è Issues detected (red)
- **Checks:**
  - Twilio configured
  - Voice configured
  - Trigger cards exist

#### **Company Variables Table**
- **Location:** `triggers.html` lines 906-936
- **Purpose:** Auto-detect {variables} in triggers
- **Displays:** Variable name, value, status (‚úì or ‚ùå)
- **Example:** `{companyName}`, `{serviceArea}`, `{pricing}`

---

## üîå PART 5: API ENDPOINTS

### **Agent Console Endpoints**

#### **Dashboard**
```
GET /api/agent-console/:companyId/truth
  ‚Üí Returns: Runtime truth JSON (full company config)
```

#### **Agent 2.0 Configuration**
```
GET  /api/agent-console/:companyId/agent2/config
  ‚Üí Returns: Agent 2.0 settings, trigger stats

PATCH /api/agent-console/:companyId/agent2/config
  ‚Üí Updates: Greetings, consent phrases, escalation phrases, discovery style

POST /api/agent-console/:companyId/agent2/test-turn
  ‚Üí Runs: Live test of discovery flow with session state
```

#### **Greetings API**
```
GET  /api/admin/agent2/:companyId/greetings
  ‚Üí Returns: Complete greetings config

PUT  /api/admin/agent2/:companyId/greetings/call-start
  ‚Üí Updates: Call start greeting (enabled, text)

POST /api/admin/agent2/:companyId/greetings/call-start/audio
  ‚Üí Generates: ElevenLabs audio for call start greeting

PUT  /api/admin/agent2/:companyId/greetings/interceptor
  ‚Üí Updates: Interceptor settings (enabled, gate, intent words)

POST /api/admin/agent2/:companyId/greetings/rules
  ‚Üí Creates: New greeting rule

PATCH /api/admin/agent2/:companyId/greetings/rules/:ruleId
  ‚Üí Updates: Existing greeting rule (enabled, text, priority, etc.)

DELETE /api/admin/agent2/:companyId/greetings/rules/:ruleId
  ‚Üí Deletes: Greeting rule

POST /api/admin/agent2/:companyId/greetings/rules/:ruleId/audio
  ‚Üí Generates: ElevenLabs audio for rule response

POST /api/admin/agent2/:companyId/greetings/seed-global
  ‚Üí Loads: Platform default greeting rules
```

#### **Triggers API**
```
GET  /api/admin/agent2/company/:companyId/triggers
  ‚Üí Returns: All triggers (global + local), stats, permissions

POST /api/admin/agent2/company/:companyId/triggers
  ‚Üí Creates: New local trigger

PATCH /api/admin/agent2/company/:companyId/triggers/:triggerId
  ‚Üí Updates: Trigger (scope, enabled, text, etc.)

DELETE /api/admin/agent2/company/:companyId/triggers/:triggerId
  ‚Üí Deletes: Local trigger or disables global trigger

POST /api/admin/agent2/:companyId/generate-trigger-audio
  ‚Üí Generates: ElevenLabs audio for trigger answer

POST /api/admin/agent2/:companyId/gpt-prefill
  ‚Üí Auto-fills: Trigger content using GPT-4
```

#### **Global Trigger Groups**
```
GET  /api/admin/agent2/global/groups
  ‚Üí Returns: Available global trigger groups

POST /api/admin/agent2/global/groups
  ‚Üí Creates: New global trigger group

PATCH /api/admin/agent2/company/:companyId/active-group
  ‚Üí Updates: Active global group for company
```

### **Twilio Webhooks**
```
POST /api/v2/twilio/voice
  ‚Üí Entry point: Call arrives, send initial greeting

POST /api/v2/twilio/gather
  ‚Üí Turn handler: Process caller speech, generate response

POST /api/v2/twilio/status
  ‚Üí Status updates: Call completed, failed, busy, etc.
```

---

## üó∫Ô∏è PART 6: COMPLETE TURN-BY-TURN CALL FLOW

### **Turn 0: Call Starts**
```
STAGE: CALL_START
TWILIO ‚Üí /api/v2/twilio/voice

1. Twilio forwards call with From, To, CallSid
2. Lookup company by To phone number
3. Load company.aiAgentSettings.agent2
4. Initialize call state (StateStore/Redis)
5. Compute awHash + effectiveConfigVersion
6. Check callStart.enabled
7. If true ‚Üí Load callStart.text
8. Validate greeting text (prevent code injection)
9. If callStart.audioUrl exists:
     ‚Üí TwiML: <Play>https://.../greetings/call-start.mp3</Play>
   Else:
     ‚Üí TwiML: <Say>Penguin Air! This is John, how can I help you?</Say>
10. TwiML: <Gather input="speech" timeout="5">
11. Return TwiML to Twilio
12. Twilio plays greeting, listens for response
```

### **Turn 1: Caller Greets**
```
STAGE: GREETING_INTERCEPTOR
CALLER: "Hi"
TWILIO ‚Üí /api/v2/twilio/gather (SpeechResult="hi")

1. Receive STT result: "hi"
2. STT Preprocessing:
   - Remove fillers (um, uh)
   - Apply corrections
3. Check word count: 1 word ‚â§ maxWords (2) ‚úì
4. Check intent words: "hi" contains none ‚úì
5. Load interceptor.rules (sorted by priority)
6. Match rule:
   - Rule #1: triggers=["hi", "hello"], matchType=FUZZY
   - Match: ‚úì
7. Load rule.response: "Hi! How can I help you today?"
8. Check rule.audioUrl:
   - If exists ‚Üí TwiML: <Play>https://.../greetings/rule-123.mp3</Play>
   - Else ‚Üí TwiML: <Say>Hi! How can I help you today?</Say>
9. TwiML: <Gather input="speech" timeout="5">
10. Return TwiML
```

### **Turn 2: Caller States Intent**
```
STAGE: DISCOVERY_ENGINE
CALLER: "My AC is not cooling"
TWILIO ‚Üí /api/v2/twilio/gather (SpeechResult="my ac is not cooling")

1. Receive STT result: "my ac is not cooling"
2. Check greeting interceptor:
   - Word count: 5 words > maxWords (2) ‚Üí skip interceptor ‚úó
3. Proceed to Discovery Engine
4. Load active trigger group (e.g., "hvac")
5. Load local triggers
6. Merge: globals + locals (locals override)
7. Sort by priority (ascending)
8. Match triggers:
   - Trigger #1: ruleId="hvac.ac_not_cooling"
     - Keywords: ["ac", "not cooling"] ‚Üí all found ‚úì
     - Negative: ["tune-up"] ‚Üí not found ‚úì
     - Match: ‚úì
9. Check response mode:
   - Standard mode:
     - Load answer.text
     - Check answer.audioUrl
     - If exists ‚Üí <Play>
     - Else ‚Üí <Say>
   - LLM mode:
     - Send to OpenAI with llm.included + llm.excluded
     - Generate response
     - Convert to TTS via ElevenLabs
     - <Play> generated audio
10. Load followup: "Would you like me to schedule a technician?"
11. TwiML: <Say>Our AC repair service is $129...</Say>
12. TwiML: <Say>Would you like me to schedule a technician?</Say>
13. TwiML: <Gather input="speech" timeout="5">
14. Return TwiML
```

### **Turn 3: Booking Consent**
```
STAGE: BOOKING_CONSENT
CALLER: "Yes please"
TWILIO ‚Üí /api/v2/twilio/gather (SpeechResult="yes please")

1. Receive STT result: "yes please"
2. Check consent phrases: ["yes", "yeah", "sure", "ok", "yes please"]
   - Match: ‚úì
3. Build handoff payload (AC1 contract):
   {
     handoffContractVersion: "AC1",
     companyId: "...",
     callSid: "...",
     fromPhone: "+15551234567",
     assumptions: {
       firstName: "Unknown",
       lastName: ""
     },
     summary: {
       issue: "AC not cooling",
       serviceType: "hvac_repair",
       urgency: "routine"
     }
   }
4. Store payload in call state
5. Hand off to Booking Logic
6. TwiML: <Say>Great! Let me get some information...</Say>
7. TwiML: <Gather input="speech" timeout="5">
```

### **Turn 4-N: Booking Flow**
```
STAGE: BOOKING_LOGIC
BOOKING ENGINE TAKES OVER

4. Ask for name ‚Üí "Can I get your first and last name?"
5. Extract name from response
6. Ask for preferred date/time
7. Check Google Calendar availability
8. Offer time slots
9. Confirm appointment
10. Send confirmation
11. TwiML: <Say>You're all set! We'll see you Thursday at 2 PM.</Say>
12. TwiML: <Hangup/>
```

### **Turn X: Escalation Path**
```
STAGE: ESCALATION
CALLER: "I want to speak to a human"
TWILIO ‚Üí /api/v2/twilio/gather (SpeechResult="i want to speak to a human")

1. Receive STT result: "i want to speak to a human"
2. Check escalation phrases: ["speak to a human", "talk to someone"]
   - Match: ‚úì
3. Load transfer number from company config
4. TwiML: <Say>Let me connect you to our team.</Say>
5. TwiML: <Dial>+15551234567</Dial>
6. Transfer call
```

---

## üìä PART 7: STATE MANAGEMENT

### **Call State (StateStore/Redis)**
```javascript
{
  callSid: "CA1234...",
  companyId: "comp_abc123",
  fromPhone: "+15551234567",
  
  // Current mode
  mode: "DISCOVERY" | "BOOKING" | "ESCALATED",
  
  // Turn counter
  turn: 3,
  
  // Discovery state
  callerName: "John Smith",
  intent: "AC not cooling",
  lastTriggerMatched: "hvac.ac_not_cooling",
  
  // Booking state
  bookingCtx: {
    firstName: "John",
    lastName: "Smith",
    issue: "AC not cooling",
    preferredDate: "2026-02-27",
    preferredTime: "14:00"
  },
  
  // Conversation history
  turns: [
    { turn: 1, input: "hi", output: "Hi! How can I help you today?" },
    { turn: 2, input: "my ac is not cooling", output: "Our AC repair..." },
    { turn: 3, input: "yes please", output: "Great! Let me..." }
  ],
  
  // AW Truth Proof
  awHash: "sha256:abc123...",
  effectiveConfigVersion: "2026-02-24T12:00:00Z"
}
```

### **Session State (Frontend Test Panel)**
```javascript
// Used for Live Test Turn in agent2.html
{
  mode: "DISCOVERY",
  turn: 0,
  callerName: null,
  intent: null
}
```

---

## üé® PART 8: AUDIO SYSTEM

### **Audio Storage**
```
/public/audio/
‚îú‚îÄ‚îÄ greetings/
‚îÇ   ‚îú‚îÄ‚îÄ call-start-{companyId}.mp3
‚îÇ   ‚îî‚îÄ‚îÄ rule-{ruleId}-{companyId}.mp3
‚îî‚îÄ‚îÄ triggers/
    ‚îî‚îÄ‚îÄ {triggerId}-{companyId}.mp3
```

### **Audio Generation Flow**

**1. User Clicks "Generate"**
```
Frontend: agent2.js or triggers.js
‚Üì
POST /api/admin/agent2/{companyId}/greetings/rules/{ruleId}/audio
  Body: { text: "Hi! How can I help you?" }
‚Üì
Backend: routes/admin/greetings.js
```

**2. Backend Processes**
```javascript
1. Validate text (not empty, max length)
2. Check if audio already exists (cache hit)
3. Load company ElevenLabs settings:
   - voiceId
   - model_id
   - stability
   - similarity_boost
4. Call ElevenLabs API via v2elevenLabsService
5. Receive audio buffer
6. Generate filename: rule-{ruleId}-{companyId}.mp3
7. Write file to /public/audio/greetings/
8. Generate URL: /audio/greetings/rule-{ruleId}-{companyId}.mp3
9. Compute text hash for cache invalidation
10. Update database:
    - audioUrl
    - audioTextHash
    - audioGeneratedAt
11. Return { success: true, audioUrl, cached }
```

**3. Frontend Updates**
```javascript
1. Receive audioUrl from API
2. Update input field: inputRuleAudio.value = audioUrl
3. Show play button
4. Update status hint: "‚úÖ Audio ready"
```

### **Audio Cache Invalidation**

**Problem:** User edits response text after generating audio

**Solution:** Text hash comparison
```javascript
const currentHash = hashText(newText);
const storedHash = rule.audioTextHash;

if (currentHash !== storedHash) {
  // Text changed ‚Üí audio is stale
  rule.audioUrl = null;
  showWarning("Text changed ‚Äî please regenerate audio");
}
```

### **Audio Playback**

**Play Button Logic:**
```javascript
function playRuleAudio() {
  // Stop any currently playing audio
  if (state.currentAudioPlayer) {
    state.currentAudioPlayer.pause();
    state.currentAudioPlayer = null;
    btnPlayRuleAudio.innerHTML = 'Play';
    return;
  }
  
  // Add cache-busting parameter
  const audioUrl = inputRuleAudio.value;
  const cacheBuster = `_cb=${Date.now()}`;
  const url = `${audioUrl}?${cacheBuster}`;
  
  // Create and play
  state.currentAudioPlayer = new Audio(url);
  btnPlayRuleAudio.innerHTML = 'Stop';
  
  state.currentAudioPlayer.onended = () => {
    state.currentAudioPlayer = null;
    btnPlayRuleAudio.innerHTML = 'Play';
  };
  
  state.currentAudioPlayer.play();
}
```

---

## üîê PART 9: AUTHENTICATION & AUTHORIZATION

### **Authentication Module**
**File:** `public/agent-console/lib/auth.js`

**Purpose:** Centralized JWT authentication for all Agent Console pages

**Functions:**
```javascript
AgentConsoleAuth = {
  // Check if user is authenticated
  requireAuth(): boolean
  
  // Make authenticated API request
  apiFetch(url, options): Promise<Response>
  
  // Logout and redirect
  logout(): void
}
```

### **Permission System**
**Backend:** `middleware/rbac.js`

**Permissions:**
```javascript
PERMISSIONS = {
  CONFIG_READ: 'config:read',
  CONFIG_WRITE: 'config:write',
  TRIGGER_MANAGE: 'trigger:manage',
  AUDIO_GENERATE: 'audio:generate'
}
```

**Usage:**
```javascript
router.get('/:companyId/greetings', 
  authenticateJWT,
  requirePermission(PERMISSIONS.CONFIG_READ),
  async (req, res) => { ... }
);
```

### **User Roles**
```
ADMIN - Full access (all permissions)
MANAGER - Config read/write, trigger manage
VIEWER - Config read only
```

---

## üìù PART 10: MODALS DEEP DIVE

### **Modal Architecture**

**Base Structure:**
```html
<div class="modal-backdrop" id="modal-{name}">
  <div class="modal">
    <div class="modal-header">
      <h3 class="modal-title">...</h3>
      <button class="btn btn-ghost btn-icon" id="modal-{name}-close">√ó</button>
    </div>
    <div class="modal-body">
      <!-- Form fields -->
    </div>
    <div class="modal-footer">
      <button class="btn btn-secondary" id="btn-{name}-cancel">Cancel</button>
      <button class="btn btn-primary" id="btn-{name}-save">Save</button>
    </div>
  </div>
</div>
```

### **Modal State Management**

**Open Modal:**
```javascript
function openGreetingRuleModal() {
  state.currentGreetingRule = null;
  
  // Reset form
  DOM.inputRulePriority.value = '50';
  DOM.inputRuleMatchType.value = 'EXACT';
  DOM.inputRuleTriggers.value = '';
  DOM.inputRuleResponse.value = '';
  
  // Show modal
  DOM.modalGreetingRule.classList.add('active');
}
```

**Close Modal:**
```javascript
function closeGreetingRuleModal() {
  DOM.modalGreetingRule.classList.remove('active');
  state.currentGreetingRule = null;
}
```

**Save Modal:**
```javascript
async function saveGreetingRule() {
  // Validate
  if (!DOM.inputRuleTriggers.value.trim()) {
    showToast('error', 'Triggers Required');
    return;
  }
  
  // Build payload
  const payload = {
    priority: parseInt(DOM.inputRulePriority.value),
    matchType: DOM.inputRuleMatchType.value,
    triggers: DOM.inputRuleTriggers.value.split(',').map(t => t.trim()),
    response: DOM.inputRuleResponse.value.trim()
  };
  
  // API call
  if (state.currentGreetingRule) {
    // Update
    await apiFetch(`/api/admin/agent2/${companyId}/greetings/rules/${ruleId}`, {
      method: 'PATCH',
      body: payload
    });
  } else {
    // Create
    await apiFetch(`/api/admin/agent2/${companyId}/greetings/rules`, {
      method: 'POST',
      body: payload
    });
  }
  
  // Refresh UI
  renderGreetingRules();
  closeGreetingRuleModal();
}
```

---

## üéØ CALL 2.0 DESIGN - RECOMMENDATIONS

### **What's Missing for Enterprise-Level Call Review**

Based on this audit, here's what Call 2.0 needs:

#### **1. Turn-by-Turn Visualization**
- Timeline view of entire call
- Each turn shows:
  - Timestamp
  - Stage (GREETING, DISCOVERY, BOOKING, etc.)
  - Caller input (STT result)
  - Matched rule (trigger, greeting, etc.)
  - Agent response
  - Audio played/generated
  - State changes

#### **2. Decision Tree Tracing**
- Show WHY each decision was made
- Example:
  ```
  Turn 2: "my ac is not cooling"
  ‚îú‚îÄ Greeting Interceptor: SKIPPED (5 words > maxWords)
  ‚îú‚îÄ Discovery Engine: ENTERED
  ‚îÇ  ‚îú‚îÄ Trigger #1 (hvac.tune_up): ‚ùå Negative match ("not cooling")
  ‚îÇ  ‚îú‚îÄ Trigger #2 (hvac.ac_not_cooling): ‚úÖ MATCHED
  ‚îÇ  ‚îÇ  ‚îú‚îÄ Keywords: ["ac", "not cooling"] ‚Üí all found
  ‚îÇ  ‚îÇ  ‚îú‚îÄ Negative: ["tune-up"] ‚Üí none found
  ‚îÇ  ‚îÇ  ‚îî‚îÄ Priority: 10 (highest)
  ‚îÇ  ‚îî‚îÄ Response: Standard mode (pre-recorded audio)
  ‚îî‚îÄ TwiML: <Play>https://.../ac-not-cooling.mp3</Play>
  ```

#### **3. Config Snapshot Preservation**
- Store exact config used during call (awHash + effectiveConfigVersion)
- Allow Call 2.0 to load historic config for replay
- Show diffs between call config and current config

#### **4. Audio Audit Trail**
- Track which audio files were played
- Show if audio was:
  - Pre-recorded (ElevenLabs generated)
  - Live TTS (fallback)
  - Stale (text changed after generation)

#### **5. Error & Fallback Tracking**
- LLM failures ‚Üí backup answer used
- Audio generation failures ‚Üí TTS fallback
- Transfer failures ‚Üí recovery path

#### **6. Conversation Memory Integration**
- Read V111 ConversationMemory records
- Show:
  - Slots extracted
  - Routing decisions
  - Turn records

---

## üìä TRUTH FOLDER STRUCTURE

```
/truth/
‚îú‚îÄ‚îÄ AGENT-CONSOLE-COMPREHENSIVE-AUDIT.md    (this file)
‚îú‚îÄ‚îÄ CALL-FLOW-DIAGRAM.md                    (visual flowchart)
‚îú‚îÄ‚îÄ API-REFERENCE.md                        (endpoint documentation)
‚îú‚îÄ‚îÄ DATABASE-SCHEMA.md                      (data models)
‚îú‚îÄ‚îÄ AUDIO-SYSTEM.md                         (audio generation & caching)
‚îú‚îÄ‚îÄ MODALS-REFERENCE.md                     (all modals & UI components)
‚îî‚îÄ‚îÄ CALL-2.0-SPECIFICATION.md               (requirements for Call 2.0)
```

---

## üîç NEXT STEPS FOR CALL 2.0

1. **Read V111 ConversationMemory spec** (`docs/architecture/V111-ConversationMemory-Spec.md`)
2. **Design Call 2.0 UI** (timeline, decision tree, config diff viewer)
3. **Build backend API** for historic call replay
4. **Create call replay engine** (load config snapshot, re-run matching logic)
5. **Add tracing instrumentation** to existing services
6. **Build truth folder exporter** (snapshot all configs for a call)

---

**END OF COMPREHENSIVE AUDIT**

*This document represents a complete, world-class mapping of the Agent Console system as of February 24, 2026. All file paths, line numbers, and code references are accurate and production-grade.*
